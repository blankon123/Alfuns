QuanzError <- testKmeans$VarQE[[nItter]]                      #Quantization Error
Cluster <- matrix(unlist(testKmeans$clusters[[10]]))
cbind.data.frame(as.matrix(row.names(y)),Cluster)    #cluster result dataview
#Plot Convergence
plot(unlist(testKmeans$VarQE),type="n", main="Convergence", xlab="Iteration", ylab="Quantization Error")
lines(unlist(testKmeans$VarQE),type="o") #Output show up in groupbox convergence
#Plot cluster
plot.new()
clusplot(y,testKmeans$clusters[[10]],main="Cluster Plot",color=TRUE,shade=TRUE, labels=2, lines=0) #Output show up in groupbox cluster plot
#Jika Error loading package, uncomment line 2
#install.packages(c("XLConnect"))
library(psych)
library(xlsx)
library(XLConnect)
### INPUT ###
z <- attitude
f <- 2 #number of factor
### OUTPUT ###
fa.parallel(attitude) #Plot Number Of Factor
blah <- capture.output(KMO(cor(attitude)))
print(blah)
#MSA Value if Correlation checked - Output show up in groupbox MSA value
KMO(cov(attitude))    #MSA value if covariance checked - Output show up in groupbox MSA Value
testFA <- principal(attitude, 2, rotate="varimax") #rotate tergantung checkbox 'rotate'
fa.diagram(testFA)    #Factor Diagram - Output show up in groupbox Factor diagram
scoring <- testFA$scores        #Scoring - Output show up in Factor Scores dataview
scoring[,2]
commun <- (testFA$communality) #Communality - Output
commun
write.xlsx(commun, "c:/temp/mydata2.xls")
y1 <- iris[1:2]
y2 <- iris[3:4]
y3 <- cbind(y1,y2)
y3
write.xlsx(y1, "c:/temp/mydata.xls")
ydata = read.xlsx("C:/temp/mydata.xls",1)
ydata
library(class)
library(cluster)
#Jika Error loading package, uncomment line 4
#install.packages(c("clv", "fpc"))
library(clv)
library(fpc)
####################################################
############## MY KMEANS GONNA START HERE ##########
####################################################
### INPUT ###
nItter <- 10 #iteration
k <- 3 #centroid
x <- USArrests
y <- read.xlsx("C:/temp/mydata.xls",1)
y
y <- y[2:ncol(y)]
### METHOD ###
myKmeans <- function(x, k, nItter) {
#create random centroid
centroid_acak <- sample(c(1:length(x[,1])), k, replace = FALSE)
centroid <- x[centroid_acak,1:length(x)]
#count euclidean distance
hitung_jarak <- function(x){
sqrt(
for(i in 1:length(x)) {
euclidean <- ((x[i] - centroid[1:k,i])^2)
euclidean <- euclidean + euclidean
return(euclidean)
}
)
}
#for trace
clusterHistory <- vector(nItter, mode='list')
centroidHistory <- vector(nItter, mode="list")
varianceHistory <- vector(nItter, mode="list")
for(i in 1:nItter) {
jarak <- t(apply(as.matrix(x), 1, hitung_jarak)) #returns matrix of distance
clusters <- apply(jarak, 1, which.min)           #assign objects to cluster based the shortest distance
centroid <- apply(x, 2, tapply, clusters, mean)  #update centroid
Var <- apply(jarak, 2, tapply, clusters, mean)   #Variance with quantization error
VarQE <- mean(diag(Var))                         #Variance with quantization error
clusterHistory[[i]] <- clusters
centroidHistory[[i]] <- centroid
varianceHistory[[i]] <- VarQE
centroid <- centroid
}
list(clusters=clusterHistory, centroid=centroidHistory, VarQE=varianceHistory)
}
## TEST KMEANS FUNCTION ##
testKmeans <- myKmeans(y, 3, 10)
testKmeans$centroid
testKmeans$clusters
testKmeans$VarQE
### OUTPUT ###
#Output Intracluster, Intercluster, Quantization Error
clsInteger <- as.integer(testKmeans$clusters[[10]])
Validcls <- cls.scatt.data(y,clsInteger)
Intracls <- mean(Validcls$intracls.average) #Intraclass
preInter <- Validcls$intercls.average ###NEW
to.upper <- function(X) X[upper.tri(X,diag=FALSE)] ###NEW
Intercls <- mean(to.upper(preInter))       ###EDITED
QuanzError <- testKmeans$VarQE[[nItter]]                      #Quantization Error
Cluster <- matrix(unlist(testKmeans$clusters[[10]]))
cbind.data.frame(as.matrix(row.names(y)),Cluster)    #cluster result dataview
#Plot Convergence
plot(unlist(testKmeans$VarQE),type="n", main="Convergence", xlab="Iteration", ylab="Quantization Error")
lines(unlist(testKmeans$VarQE),type="o") #Output show up in groupbox convergence
#Plot cluster
plot.new()
clusplot(y,testKmeans$clusters[[10]],main="Cluster Plot",color=TRUE,shade=TRUE, labels=2, lines=0) #Output show up in groupbox cluster plot
y <- y[2:ncol(y)]
y
y <- y[1:ncol(y)]
y
y <- read.xlsx("C:/temp/mydata.xls",1)
y
y <- y[1:ncol(y)]
y
y <- read.xlsx("C:/temp/mydata.xls",1)
y
y <- y[2:ncol(y)]
y
cbind.data.frame(as.matrix(row.names(y)),Cluster)    #cluster result dataview
centroid_acak <- sample(c(1:length(x[1,])), k, replace = FALSE)
centroid_acak
centroid_acak <- sample(c(1:length(y[1,])), k, replace = FALSE)
centroid_acak
centroid_acak <- sample(c(1:length(y[,1])), k, replace = FALSE)
centroid_acak
myKmeans <- function(x, k, nItter) {
#create random centroid
centroid_acak <- sample(c(1:length(y[,1])), k, replace = FALSE)
centroid <- x[centroid_acak,1:length(x)]
#count euclidean distance
hitung_jarak <- function(x){
sqrt(
for(i in 1:length(x)) {
euclidean <- ((x[i] - centroid[1:k,i])^2)
euclidean <- euclidean + euclidean
return(euclidean)
}
)
}
#for trace
clusterHistory <- vector(nItter, mode='list')
centroidHistory <- vector(nItter, mode="list")
varianceHistory <- vector(nItter, mode="list")
for(i in 1:nItter) {
jarak <- t(apply(as.matrix(x), 1, hitung_jarak)) #returns matrix of distance
clusters <- apply(jarak, 1, which.min)           #assign objects to cluster based the shortest distance
centroid <- apply(x, 2, tapply, clusters, mean)  #update centroid
Var <- apply(jarak, 2, tapply, clusters, mean)   #Variance with quantization error
VarQE <- mean(diag(Var))                         #Variance with quantization error
clusterHistory[[i]] <- clusters
centroidHistory[[i]] <- centroid
varianceHistory[[i]] <- VarQE
centroid <- centroid
}
list(clusters=clusterHistory, centroid=centroidHistory, VarQE=varianceHistory)
}
testKmeans <- myKmeans(y, 3, 10)
testKmeans2 <- myKmeans(y, 4, 17)
testKmeans <- myKmeans(y, 3, 10)
testKmeans2 <- myKmeans(y, 4, 17)
testKmeans <- myKmeans(y, 3, 10)
testKmeans2 <- myKmeans(y, 5, 20)
library(class)
library(cluster)
library(clv)
library(fpc)
####################################################
############## MY PSO GONNA START HERE #############
####################################################
### INPUT ###
#Constants PSO
c1 <- 1.49
c2 <- 1.49
w <- 0.72
k <- 3
x <- USArrests
y <- iris[1:4]
nItter <- 101
### METHOD ###
myPSO <- function(x, k, nItter, c1, c2, w) {
#Create Random centroid
centroid_acak <- sample(c(1:length(x[,1])), k, replace = FALSE)
centroid <- x[centroid_acak,1:length(x)]
#count euclidean distance
hitung_jarak <- function(x){
sqrt(
for(i in 1:length(x)) {
euclidean <- ((x[i] - centroid[1:k,i])^2)
euclidean <- euclidean + euclidean
return(euclidean)
}
)
}
#Fitness Function Cluster
OF <- function(x){
jarak <- t(apply(as.matrix(x), 1, hitung_jarak))  #returns matrix of distance
clusters <- apply(jarak, 1, which.min)         #assign objects to cluster based the shortest distance
Var <- apply(jarak, 2, tapply, clusters, mean)   #Variance with quantization error
VarQE <- mean(diag(Var))                         #Variance with quantization error
tabclust <- diag(1/table(factor(clusters, levels=1:k)))         #Fitness Function
quantError <- as.matrix(rowSums(jarak %*% tabclust)/k)          #Fitness Function
return(quantError)
}
#Matrix Random Uniform
mRU <- function(x)
# returns a matrix of size mxn of uniform random variates
{
return(array(runif(k*length(x)), dim = c(k,length(x))))
}
#initialize position and velocity
mP <- x
mV <- matrix(0,k,length(x))
#count fitness function
vF <- OF(x)
#Matrix Best Solutions
mPbest <- mP                 # matrix of `personally best' solutions
vFbest <- vF                 # vector of OF of best solutions
sGbest <- min(vFbest)            # scalar: best OF-value
sgbest <- which.min(vFbest)[1]    # scalar: best solution (counter)
#for trace
clusterHistory <- vector(nItter, mode="list")
centroidHistory <- vector(nItter, mode="list")
varianceHistory <- vector(nItter, mode="list")
for(i in 1:nItter) {
#update centroid
mDV <- c1 * mRU(x) * (mPbest[row.names(centroid),] - centroid) + c2 * mRU(x) * (matrix(mPbest[sgbest,]) - centroid)
mV  <- w * mV + mDV
centroid  <- centroid + mV
centroid <- centroid
#count fitness function
#vF <- OF(x)
jarak <- t(apply(as.matrix(x), 1, hitung_jarak))  #returns matrix of distance
clusters <- apply(jarak, 1, which.min)         #assign objects to cluster based the shortest distance
Var <- apply(jarak, 2, tapply, clusters, mean)   #Variance with quantization error
VarQE <- mean(diag(Var))                         #Variance with quantization error
tabclust <- diag(1/table(factor(clusters, levels=1:k)))         #Fitness Function
quantError <- as.matrix(rowSums(jarak %*% tabclust)/k)          #Fitness Function
vF <- quantError
# find improvements
logik <- vF < vFbest        # improved solutions
mPbest[logik,] <- mP[logik,]
vFbest[logik] <- vF[logik]
# find best solution
if (min(vF) < sGbest){
sGbest <- min(vF)
sgbest <- which.min(vF)[1]
}
clusterHistory[[i]] <- clusters
centroidHistory[[i]] <- centroid
varianceHistory[[i]] <- VarQE
}
list(clusters=clusterHistory, centroid=centroidHistory, VarQE=varianceHistory)
}
## TEST PSO FUNCTION ##
testPSO <- myPSO(y,k,101,c1,c2,w)
### OUTPUT ###
#Output Intracluster and Intercluster
clsInteger <- as.integer(testPSO$clusters[[100]])
Validcls <- cls.scatt.data(y,clsInteger)
Intracls <- mean(Validcls$intracls.average) #Output show up in groupbox Validity
preInter <- Validcls$intercls.average ###NEW
to.upper <- function(X) X[upper.tri(X,diag=FALSE)] ###NEW
Intercls <- mean(to.upper(preInter))       ### EDITED:Output shop up in groupbox Validity
print("ASD"+Intercls)
QuanzError <- testPSO$VarQE[[100]]                      #Output shop up in groupbox Validity
Cluster <- matrix(unlist(testPSO$clusters[[100]]))
clusterResultDataView <- cbind.data.frame(y,Cluster)                 #Output show up in cluster result dataview
clusterResultDataView[2:ncol(clusterResultDataView)]
#Plot Convergence
plot(unlist(testPSO$VarQE),type="n", main="Convergence", xlab="Iteration", ylab="Quantization Error")
lines(unlist(testPSO$VarQE),type="o") #Output show up in groupbox convergence
#Plot cluster
plot.new()
clusplot(y,testPSO$clusters[[100]],main="Cluster Plot",color=TRUE,shade=TRUE, labels=2, lines=0) #Output show up in groupbox cluster plot
print(Intercls)
library(class)
library(cluster)
#Jika Error loading package, uncomment line 4
#install.packages(c("clv", "fpc"))
library(clv)
library(fpc)
####################################################
############## MY KMEANS GONNA START HERE ##########
####################################################
### INPUT ###
nItter <- 10 #iteration
k <- 3 #centroid
x <- USArrests
y <- read.xlsx("C:/temp/mydata.xls",1)
y
y <- y[2:ncol(y)]
y
### METHOD ###
myKmeans <- function(x, k, nItter) {
#create random centroid
centroid_acak <- sample(c(1:length(x[,1])), k, replace = FALSE)
centroid <- x[centroid_acak,1:length(x)]
#count euclidean distance
hitung_jarak <- function(x){
sqrt(
for(i in 1:length(x)) {
euclidean <- ((x[i] - centroid[1:k,i])^2)
euclidean <- euclidean + euclidean
return(euclidean)
}
)
}
#for trace
clusterHistory <- vector(nItter, mode='list')
centroidHistory <- vector(nItter, mode="list")
varianceHistory <- vector(nItter, mode="list")
for(i in 1:nItter) {
jarak <- t(apply(as.matrix(x), 1, hitung_jarak)) #returns matrix of distance
clusters <- apply(jarak, 1, which.min)           #assign objects to cluster based the shortest distance
centroid <- apply(x, 2, tapply, clusters, mean)  #update centroid
Var <- apply(jarak, 2, tapply, clusters, mean)   #Variance with quantization error
VarQE <- mean(diag(Var))                         #Variance with quantization error
clusterHistory[[i]] <- clusters
centroidHistory[[i]] <- centroid
varianceHistory[[i]] <- VarQE
centroid <- centroid
}
list(clusters=clusterHistory, centroid=centroidHistory, VarQE=varianceHistory)
}
## TEST KMEANS FUNCTION ##
testKmeans <- myKmeans(y, 3, 10)
testKmeans2 <- myKmeans(y, 5, 20)
testKmeans$centroid
testKmeans$clusters
testKmeans$VarQE
### OUTPUT ###
#Output Intracluster, Intercluster, Quantization Error
clsInteger <- as.integer(testKmeans$clusters[[10]])
Validcls <- cls.scatt.data(y,clsInteger)
Intracls <- mean(Validcls$intracls.average) #Intraclass
preInter <- Validcls$intercls.average ###NEW
to.upper <- function(X) X[upper.tri(X,diag=FALSE)] ###NEW
Intercls <- mean(to.upper(preInter))       ###EDITED
QuanzError <- testKmeans$VarQE[[nItter]]                      #Quantization Error
Cluster <- matrix(unlist(testKmeans$clusters[[10]]))
cbind.data.frame(as.matrix(row.names(y)),Cluster)    #cluster result dataview
#Plot Convergence
plot(unlist(testKmeans$VarQE),type="n", main="Convergence", xlab="Iteration", ylab="Quantization Error")
lines(unlist(testKmeans$VarQE),type="o") #Output show up in groupbox convergence
library(xlsx)
library(xlsx)
library(car)
install.packages('car')
library(car)
setwd("~/Skripsi Alfi")
data <- read.xlsx(file = 'perempuan.xls',sheetIndex = 1)
View(data)
fit <- lm(mpg~disp+hp+wt+drat, data=mtcars)
outlierTest(fit) # Bonferonni p-value for most extreme obs
fit <- lm(AU~AGE+BMI, data=data)
outlierTest(fit) # Bonferonni p-value for most extreme obs
qqPlot(fit, main="QQ Plot") #qq plot for studentized resid
# Normality of Residuals
# qq plot for studentized resid
qqPlot(fit, main="QQ Plot")
# distribution of studentized residuals
library(MASS)
sresid <- studres(fit)
hist(sresid, freq=FALSE,
main="Distribution of Studentized Residuals")
xfit<-seq(min(sresid),max(sresid),length=40)
yfit<-dnorm(xfit)
lines(xfit, yfit)
# Evaluate homoscedasticity
# non-constant error variance test
ncvTest(fit)
# plot studentized residuals vs. fitted values
spreadLevelPlot(fit)
# Evaluate Collinearity
vif(fit) # variance inflation factors
sqrt(vif(fit)) > 2 # problem?
# Evaluate Nonlinearity
# component + residual plot
crPlots(fit)
# Ceres plots
ceresPlots(fit)
# Test for Autocorrelated Errors
durbinWatsonTest(fit)
library(gvlma)
outlierTest(fit) # Bonferonni p-value for most extreme obs
qqPlot(fit, main="QQ Plot") #qq plot for studentized resid
leveragePlots(fit) # leverage plots
# Normality of Residuals
# qq plot for studentized resid
qqPlot(fit, main="QQ Plot")
# distribution of studentized residuals
library(MASS)
sresid <- studres(fit)
hist(sresid, freq=FALSE,
main="Distribution of Studentized Residuals")
xfit<-seq(min(sresid),max(sresid),length=40)
yfit<-dnorm(xfit)
lines(xfit, yfit)
# Evaluate homoscedasticity
# non-constant error variance test
ncvTest(fit)
# plot studentized residuals vs. fitted values
spreadLevelPlot(fit)
# Evaluate Collinearity
vif(fit) # variance inflation factors
sqrt(vif(fit)) > 2 # problem?
# Evaluate Nonlinearity
# component + residual plot
crPlots(fit)
# Ceres plots
ceresPlots(fit)
# Test for Autocorrelated Errors
durbinWatsonTest(fit)
# Normality of Residuals
# qq plot for studentized resid
qqPlot(fit, main="QQ Plot")
# distribution of studentized residuals
library(MASS)
sresid <- studres(fit)
hist(sresid, freq=FALSE,
main="Distribution of Studentized Residuals")
xfit<-seq(min(sresid),max(sresid),length=40)
yfit<-dnorm(xfit)
lines(xfit, yfit)
# Evaluate homoscedasticity
# non-constant error variance test
ncvTest(fit)
# plot studentized residuals vs. fitted values
spreadLevelPlot(fit)
outlierTest(fit) # Bonferonni p-value for most extreme obs
summary(fit)
mean(data['age'])
mean(data['AGE'])
mean(data.AGE)
data.AGE
data['AGE']
mean(data['AGE'])
mean(data['AGE'][])
mean(d)
d <- data['AGE']
mean(d)
apply(data,'AGE',mean)
sapply(data,mean)
summary(fit)
outlierTest(fit) # Bonferonni p-value for most extreme obs
qqPlot(fit, main="QQ Plot") #qq plot for studentized resid
leveragePlots(fit) # leverage plots
# Normality of Residuals
# qq plot for studentized resid
qqPlot(fit, main="QQ Plot")
# distribution of studentized residuals
library(MASS)
sresid <- studres(fit)
hist(sresid, freq=FALSE,
main="Distribution of Studentized Residuals")
xfit<-seq(min(sresid),max(sresid),length=40)
yfit<-dnorm(xfit)
lines(xfit, yfit)
# Evaluate homoscedasticity
# non-constant error variance test
ncvTest(fit)
# plot studentized residuals vs. fitted values
spreadLevelPlot(fit)
# Evaluate homoscedasticity
# non-constant error variance test
ncvTest(fit)
# plot studentized residuals vs. fitted values
spreadLevelPlot(fit)
# Evaluate Collinearity
vif(fit) # variance inflation factors
sqrt(vif(fit)) > 2 # problem?
# Evaluate Nonlinearity
# component + residual plot
crPlots(fit)
# Ceres plots
ceresPlots(fit)
# Test for Autocorrelated Errors
durbinWatsonTest(fit)
library(gvlma)
gvmodel <- gvlma(fit)
summary(gvmodel)
# Evaluate Collinearity
vif(fit) # variance inflation factors
sqrt(vif(fit)) > 2 # problem?
# Tes pake durbin-watson
durbinWatsonTest(fit)
# Evaluate homoscedasticity
# non-constant error variance test
ncvTest(fit)
# plot studentized residuals vs. fitted values
spreadLevelPlot(fit)
ncvTest(fit)
# plot studentized residuals vs. fitted values
spreadLevelPlot(fit) #relatif Random artinya
# Normality of Residuals
# qq plot for studentized resid
qqPlot(fit, main="QQ Plot")
# distribution of studentized residuals
library(MASS)
hist(sresid, freq=FALSE,
main="Distribution of Studentized Residuals")
xfit<-seq(min(sresid),max(sresid),length=40)
yfit<-dnorm(xfit)
lines(xfit, yfit)#plot menunjukkan relatif normal
# Untuk mengecek Homoskedastisitas
# Evaluate Nonlinearity
# component + residual plot
crPlots(fit)
# Ceres plots
ceresPlots(fit)
durbinWatsonTest(fit) #nilai antara 0-4 , 2 berarti tidak ada autokol. 1.96 bagus,tidak ada autokol
